{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>MLP Predictor for stock data</h1>\n",
    "\n",
    "<h3>Author: Danilo Filippo Reiszel Pereira</h3>\n",
    "<strong>Univesidade Federal do Rio de Janeiro</strong>\n",
    "\n",
    "<p>This notebook contains the creation a Multi-layer Perceptron model to predict D+1 closing prices of stocks</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append('../src')\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from neuralstocks.dataacquisition import *\n",
    "from neuralstocks.plots import *\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense\n",
    "from keras import optimizers\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.utils import plot_model\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from IPython.display import SVG\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Global Params</h3>\n",
    "\n",
    "Setting global params such as directory of data, save directories and plot params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataPath = '../../data'\n",
    "assetType = 'stocks'\n",
    "asset = 'PETR4'\n",
    "frequency = 'diario'\n",
    "filePath = dataPath + '/' + assetType + '/' + asset + '/' + frequency + '/' + asset + '.CSV'\n",
    "\n",
    "pathPETR4 = '../../data/stocks/PETR4/diario/PETR4.CSV'\n",
    "pathIBOV = '../../data/indexes/IBOV/diario/IBOV.CSV'\n",
    "pathUSDBRL = '../../data/forex/USDBRL/diario/USDBRL.CSV'\n",
    "pathEURBRL = '../../data/forex/EURBRL/diario/EURBRL.CSV'\n",
    "\n",
    "decomposeModel = 'additive'\n",
    "\n",
    "saveVarDir = './Variables'\n",
    "if not os.path.exists(saveVarDir):\n",
    "    os.makedirs(saveVarDir)\n",
    "    print('saveVarDir created')\n",
    "else:\n",
    "    print('saveVarDir already exists!')\n",
    "saveFigDir = './Figures'\n",
    "if not os.path.exists(saveFigDir):\n",
    "    os.makedirs(saveFigDir)\n",
    "    print('saveFigDir created')\n",
    "else:\n",
    "    print('saveFigDir already exists!')\n",
    "saveModelDir = './models'\n",
    "if not os.path.exists(saveModelDir):\n",
    "    os.makedirs(saveModelDir)\n",
    "    print('saveModelDir created')\n",
    "else:\n",
    "    print('saveModelDir already exists!')\n",
    "saveFormat = 'png'\n",
    "\n",
    "plt.rcParams['font.weight'] = 'bold'\n",
    "plt.rcParams['figure.titlesize'] = 18\n",
    "plt.rcParams['figure.titleweight'] = 'bold'\n",
    "plt.rcParams['axes.titlesize'] = 15\n",
    "plt.rcParams['axes.titleweight'] = 'bold'\n",
    "plt.rcParams['axes.labelsize'] = 15\n",
    "plt.rcParams['axes.labelweight'] = 'bold'\n",
    "plt.rcParams['xtick.labelsize'] = 13\n",
    "plt.rcParams['ytick.labelsize'] = 13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Data Acquisition and Preprocessing</h3>\n",
    "\n",
    "Gathers and preprocess data. Data from auxiliary time series (such as IBOV index and USDBRL exchange rate) is also gathered, though tipically less indicators are calculated for this series. Trend Extraction is applied to desired series.\n",
    "\n",
    "<strong>List of indicators applied to main time series: </strong>\n",
    "<ul>\n",
    "    <li>Mean and Standard Deviation, 20 periods</li>\n",
    "    <li>Returns Calculations:\n",
    "        <ul>\n",
    "            <li>Close<sub>d</sub> / Close<sub>d-1</sub></li>\n",
    "            <li>Close<sub>d</sub> / Open<sub>d</sub></li>\n",
    "            <li>High<sub>d</sub> / Close<sub>d</sub></li>\n",
    "            <li>Low<sub>d</sub> / Close<sub>d</sub></li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>EMAs:\n",
    "        <ul>\n",
    "            <li>Close, 17 periods</li>\n",
    "            <li>Close, 72 periods</li>\n",
    "            <li>Close, 200 periods</li>\n",
    "            <li>Volume, 21 periods</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>MACD, fast EMA = 12 periods, slow EMA = 26 periods, signal EMA = 9 periods</li>\n",
    "    <li>Bollinger Bands, 20 periods</li>\n",
    "    <li>On-Balance Volume (OBV)</li>\n",
    "</ul>\n",
    "\n",
    "<strong>Parameters for trend extraction:</strong>\n",
    "<ul>\n",
    "    <li>Column: Close</li>\n",
    "    <li>Decompose model: Additive</li>\n",
    "    <li>Fitting Order: 1 (by default)</li>\n",
    "    <li>Window Size: 6</li>\n",
    "    <li>Fitting Weigths Model: Autocorrelation</li>\n",
    "    <li>Fitting Weigths Model Window Size: 18</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_time = time.time()\n",
    "PETR4 = acquireData(filePath = pathPETR4,\n",
    "                    replicateForHolidays = True,\n",
    "                    meanStdLen = 20,\n",
    "                    returnCalcParams = [['Close'], \n",
    "                                        ['Close', 'Open'],\n",
    "                                        ['High', 'Close' ],\n",
    "                                        ['Low', 'Close']],\n",
    "                    EMAparams = [{'column': 'Close', 'lenght': 17}, \n",
    "                                 {'column': 'Close', 'lenght': 72}, \n",
    "                                 {'column': 'Close', 'lenght': 200}, \n",
    "                                 {'column': 'Volume', 'lenght': 21}],\n",
    "                    MACDParams = [{'fast_lenght': 12, 'slow_lenght': 26, 'signal_lenght': 9}],\n",
    "                    BBParams = [{'lenght': 20}],\n",
    "                    OBVParams = [{'lenght': None}],\n",
    "                    deTrendParams = {'column': 'Close', 'window': 6, 'model': decomposeModel, \n",
    "                                     'weightModel': 'window_acorr', 'weightModelWindow': 18},\n",
    "                    colPrefix = 'PETR4',\n",
    "                    dropNan = True\n",
    "                   )\n",
    "\n",
    "IBOV = acquireData(filePath = pathIBOV,\n",
    "                    replicateForHolidays = True,\n",
    "                    meanStdLen = 20,\n",
    "                    returnCalcParams = [['Close'], \n",
    "                                        ['Close', 'Open'],\n",
    "                                        ['High', 'Close' ],\n",
    "                                        ['Low', 'Close']],\n",
    "                    EMAparams = [{'column': 'Close', 'lenght': 17}, \n",
    "                                 {'column': 'Close', 'lenght': 72}, \n",
    "                                 {'column': 'Close', 'lenght': 200}],\n",
    "                    colPrefix = 'IBOV',\n",
    "                    dropNan = True\n",
    "                  )\n",
    "\n",
    "USDBRL= acquireData(filePath = pathUSDBRL,\n",
    "                    replicateForHolidays = True,\n",
    "                    meanStdLen = 20,\n",
    "                    returnCalcParams = [['Close'], \n",
    "                                        ['Close', 'Open'],\n",
    "                                        ['High', 'Close' ],\n",
    "                                        ['Low', 'Close']],\n",
    "                    EMAparams = [{'column': 'Close', 'lenght': 17}, \n",
    "                                 {'column': 'Close', 'lenght': 72}, \n",
    "                                 {'column': 'Close', 'lenght': 200}],\n",
    "                    colPrefix = 'USDBRL',\n",
    "                    dropNan = True\n",
    "                   )\n",
    "\n",
    "\n",
    "end_time = time.time()\n",
    "print 'Time to acquire and process data: '+str(end_time-init_time)+' seconds'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Dataset concatenation and selection of wich features to feed to the model</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([PETR4, IBOV, USDBRL], axis = 1).dropna()\n",
    "\n",
    "columnsToUse = ['PETR4_Close_resid', \n",
    "                'PETR4_Close_rollStd20', \n",
    "                'PETR4_Close_returns', 'PETR4_Close/Open_returns', 'PETR4_High/Close_returns', 'PETR4_Low/Close_returns', \n",
    "                'PETR4_Close_EMA17_logdiff', 'PETR4_Close_EMA72_logdiff', 'PETR4_Close_EMA200_logdiff', 'PETR4_Volume_EMA21_logdiff', \n",
    "                'PETR4_MACD_12_26_9', 'PETR4_MACDsignal_12_26_9', 'PETR4_Bollinger%b_20', 'PETR4_OBV', \n",
    "                'PETR4_Holiday',\n",
    "                'IBOV_Close_rollStd20', \n",
    "                'IBOV_Close_returns', 'IBOV_Close/Open_returns', 'IBOV_High/Close_returns', 'IBOV_Low/Close_returns',\n",
    "                'IBOV_Close_EMA17_logdiff', 'IBOV_Close_EMA72_logdiff', 'IBOV_Close_EMA200_logdiff',\n",
    "                'USDBRL_Close_rollStd20', \n",
    "                'USDBRL_Close_returns', 'USDBRL_Close/Open_returns', 'USDBRL_High/Close_returns', 'USDBRL_Low/Close_returns',\n",
    "                'USDBRL_Close_EMA17_logdiff', 'USDBRL_Close_EMA72_logdiff', 'USDBRL_Close_EMA200_logdiff',\n",
    "               ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Creation of feature matrix and output array, split of data in Train and Test sets</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "xTrain, yTrain, xTest, yTest = prepData(df = df, \n",
    "                                        columnsToUse = columnsToUse, columnToPredict = 'PETR4_Close_resid', \n",
    "                                        nDelays = 10, testSetSize = len(df['2017'])\n",
    "                                       )\n",
    "\n",
    "numberOfTrainBatches = len(xTrain)\n",
    "numberOTestBatches = len(xTest)\n",
    "numberOfTrainInputs = len(xTrain[0])\n",
    "print 'Number of train batches: {}'.format(numberOfTrainBatches)\n",
    "print 'Number of test batches: {}'.format(numberOTestBatches)\n",
    "print 'Number of inputs per batch: {}'.format(numberOfTrainInputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Feature Scalling</h3>\n",
    "\n",
    "Technique used: Normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xNormScaler = MinMaxScaler(feature_range = (-1,1))\n",
    "xNormScaler.fit(xTrain)\n",
    "\n",
    "yNormScaler = MinMaxScaler(feature_range = (-1,1))\n",
    "yNormScaler.fit(yTrain)\n",
    "\n",
    "xNormTrain = xNormScaler.transform(xTrain)\n",
    "xNormTest  = xNormScaler.transform(xTest)\n",
    "\n",
    "yNormTrain = yNormScaler.transform(yTrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Parameters for traning</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputDim = xTrain.shape[1]\n",
    "\n",
    "nFolds = 10 # number of times a topology will be trained\n",
    "maxNeuronsInHiddenLayer = 40 # upper limit for number of neurons in hidden layer\n",
    "\n",
    "# optimizer definition\n",
    "optimizer = optimizers.SGD(lr=0.003, momentum=0.00, decay=0.0, nesterov=False)\n",
    "\n",
    "# callbacks definitions\n",
    "earlyStopping = EarlyStopping(monitor='val_loss', patience=25, mode='auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Training of MLP model</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelCheckpoint = ModelCheckpoint('Models/PETR4_MLP_norm.h5', save_best_only=True)\n",
    "\n",
    "init_time = time.time()\n",
    "\n",
    "bestNormValLoss = np.Inf\n",
    "bestNormFitHistory = None\n",
    "\n",
    "for nNeurons in range(1, maxNeuronsInHiddenLayer + 1):\n",
    "    for fold in range(nFolds):\n",
    "        model = Sequential([Dense(nNeurons, activation = 'tanh', input_dim = inputDim),\n",
    "                            Dense(1, activation = 'linear')\n",
    "                           ])\n",
    "        model.compile(optimizer = optimizer, loss = 'mean_squared_error', metrics = ['mae'])\n",
    "\n",
    "        fitHistory = model.fit(xNormTrain, \n",
    "                               yNormTrain, \n",
    "                               epochs = 500,\n",
    "                               verbose = 0,\n",
    "                               shuffle = True,\n",
    "                               validation_split = 0.15, \n",
    "                               callbacks = [modelCheckpoint,\n",
    "                                            earlyStopping])\n",
    "        \n",
    "        if min(fitHistory.history['val_loss']) < bestNormValLoss:\n",
    "            bestNormValLoss = min(fitHistory.history['val_loss'])\n",
    "            bestNormFitHistory = fitHistory\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "print 'Time to fit all models: '+str(end_time-init_time)+' seconds'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestNormModel = load_model('Models/PETR4_MLP_norm.h5')\n",
    "bestNormModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVG(model_to_dot(bestNormModel).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Plot of RMSE per epoch, for Training Set and Validation Set</h3>\n",
    "Note: Validation set is not the same as Test Set; it's randomly generated from the Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (10,10), nrows = 1, ncols = 1)\n",
    "ax.set_title('RMSE per epoch')\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('RMSE')\n",
    "trainigSet, = ax.plot(np.sqrt(bestNormFitHistory.history['loss']), 'b', label = 'trainig set')\n",
    "validationSet, = ax.plot(np.sqrt(bestNormFitHistory.history['val_loss']), 'r', label = 'validation set')\n",
    "plt.legend(handles=[trainigSet, validationSet], labels=['training set', 'validation set'], prop={'size': 15})\n",
    "plt.figtext(0.5,  0.010, 'Lowest Validation RMSE: {}'.format(min(bestNormFitHistory.history['val_loss'])), size = 14, horizontalalignment = 'center')\n",
    "fig.savefig('{}/{}.{}'.format(saveFigDir, 'PETR4_MLP_norm', 'pdf'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Plot of predictions made using the Test Set</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionsNorm = bestNormModel.predict(xNormTest)\n",
    "predictionsNorm = yNormScaler.inverse_transform(predictionsNorm)\n",
    "predictionsNorm_clean = []\n",
    "for p in predictionsNorm:\n",
    "    predictionsNorm_clean.extend(p)\n",
    "predictionsNormSeries = pd.Series(predictionsNorm_clean, index = df['2017'].index)\n",
    "\n",
    "plotSeries([df['PETR4_Close_trend']+ df['PETR4_Close_resid'], \n",
    "#            df['PETR4_Close_trend'],\n",
    "            df['PETR4_Close_trend'] + predictionsNormSeries],\n",
    "           initialPlotDate = '2017-05', finalPlotDate = '2017-06',\n",
    "           title = 'Original Data vs Predicted', ylabel = 'Price')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Plot of errors from Trend Prediction and Trend + ANN Prediction</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotSeries([df['PETR4_Close_resid'], (df['PETR4_Close_resid'] - predictionsNormSeries)],\n",
    "           plotZeroLine = True,\n",
    "           initialPlotDate = '2017-05', finalPlotDate = '2017-06',\n",
    "           title = 'Prediction Error', ylabel = 'BRL')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Retraining same topologies, but using standardization</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "xStdScaler = StandardScaler()\n",
    "xStdScaler.fit(xTrain)\n",
    "\n",
    "yStdScaler = StandardScaler()\n",
    "yStdScaler.fit(yTrain)\n",
    "\n",
    "xStdTrain = xStdScaler.transform(xTrain)\n",
    "xStdTest  = xStdScaler.transform(xTest)\n",
    "\n",
    "yStdTrain = yStdScaler.transform(yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelCheckpointStd = ModelCheckpoint('tmp/PETR4_MLP_std.h5', save_best_only=True)\n",
    "\n",
    "init_time = time.time()\n",
    "\n",
    "bestStdValLoss = np.Inf\n",
    "bestStdFitHistory = None\n",
    "\n",
    "for nNeurons in range(1, maxNeuronsInHiddenLayer + 1):\n",
    "    for fold in range(nFolds):\n",
    "        modelStd = Sequential([Dense(nNeurons, activation = 'tanh', input_dim = inputDim),\n",
    "                               Dense(1, activation = 'linear')\n",
    "                              ])\n",
    "        modelStd.compile(optimizer = optimizer, loss = 'mean_squared_error', metrics = ['mae'])\n",
    "\n",
    "        fitHistory = modelStd.fit(xStdTrain, \n",
    "                                  yStdTrain, \n",
    "                                  epochs = 500,\n",
    "                                  verbose = 0,\n",
    "                                  shuffle = True,\n",
    "                                  validation_split = 0.15, \n",
    "                                  callbacks = [modelCheckpointStd,\n",
    "                                               earlyStopping])\n",
    "        \n",
    "        if min(fitHistory.history['val_loss']) < bestStdValLoss:\n",
    "            bestStdValLoss = min(fitHistory.history['val_loss'])\n",
    "            bestStdFitHistory = fitHistory\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "print 'Time to fit all models: '+str(end_time-init_time)+' seconds'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bestModelStd = load_model('tmp/PETR4_MLP_std.h5')\n",
    "bestModelStd.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (10,10), nrows = 1, ncols = 1)\n",
    "ax.set_title('RMSE per epoch')\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('RMSE')\n",
    "trainigSet, = ax.plot(np.sqrt(bestStdFitHistory.history['loss']), 'b', label = 'trainig set')\n",
    "validationSet, = ax.plot(np.sqrt(bestStdFitHistory.history['val_loss']), 'r', label = 'validation set')\n",
    "plt.legend(handles=[trainigSet, validationSet], labels=['training set', 'validation set'], prop={'size': 15})\n",
    "plt.figtext(0.5,  0.010, 'Lowest Validation RMSE: {}'.format(min(bestStdFitHistory.history['val_loss'])), size = 14, horizontalalignment = 'center')\n",
    "fig.savefig('{}/{}.{}'.format(saveFigDir, 'PETR4_MLP_std', 'pdf'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionsStd = bestModelStd.predict(xStdTest)\n",
    "predictionsStd = yStdScaler.inverse_transform(predictionsStd)\n",
    "predictionsStd_clean = []\n",
    "for p in predictionsStd:\n",
    "    predictionsStd_clean.extend(p)\n",
    "predictionsStdSeries = pd.Series(predictionsStd_clean, index = df['2017'].index)\n",
    "\n",
    "plotSeries([df['PETR4_Close_trend']+ df['PETR4_Close_resid'], \n",
    "#            df['PETR4_Close_trend'],\n",
    "            df['PETR4_Close_trend'] + predictionsStdSeries],\n",
    "           initialPlotDate = '2017-05', finalPlotDate = '2017-06',\n",
    "           title = 'Original Data vs Predicted', ylabel = 'Price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotSeries([df['PETR4_Close_resid'], (df['PETR4_Close_resid'] - predictionsStdSeries)],\n",
    "           plotZeroLine = True,\n",
    "           initialPlotDate = '2017-05', finalPlotDate = '2017-06',\n",
    "           title = 'Prediction Error', ylabel = 'BRL')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Retraining MLPs using only the delayed series as input, no auxiliar series, for comparative purposes</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnsToUse = ['PETR4_Close_resid']\n",
    "\n",
    "xSimpleTrain, ySimpleTrain, xSimpleTest, ySimpleTest = prepData(df = df, \n",
    "                                                                columnsToUse = columnsToUse, columnToPredict = 'PETR4_Close_resid', \n",
    "                                                                nDelays = 10, testSetSize = len(df['2017']))\n",
    "\n",
    "xSimpleScaler = MinMaxScaler()\n",
    "xSimpleScaler.fit(xSimpleTrain)\n",
    "\n",
    "ySimpleScaler = MinMaxScaler()\n",
    "ySimpleScaler.fit(ySimpleTrain)\n",
    "\n",
    "xSimpleTrain = xSimpleScaler.transform(xSimpleTrain)\n",
    "xSimpleTest  = xSimpleScaler.transform(xSimpleTest)\n",
    "\n",
    "ySimpleTrain = ySimpleScaler.transform(ySimpleTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputDim = xSimpleTrain.shape[1]\n",
    "\n",
    "nFolds = 10 # number of times a topology will be trained\n",
    "maxNeuronsInHiddenLayer = 10 # upper limit for number of neurons in hidden layer\n",
    "\n",
    "modelSimple = Sequential([Dense(nNeurons, activation = 'tanh', input_dim = inputDim),\n",
    "                          Dense(1, activation = 'linear')\n",
    "                         ])\n",
    "modelSimple.compile(optimizer = optimizer, loss = 'mean_squared_error', metrics = ['mae'])\n",
    "\n",
    "print 'começou'\n",
    "fitHistory = modelSimple.fit(xSimpleTrain, \n",
    "                             ySimpleTrain, \n",
    "                             epochs = 500,\n",
    "                             verbose = 0,\n",
    "                             shuffle = True,\n",
    "                             validation_split = 0.15, \n",
    "                             callbacks = [modelCheckpointStd,\n",
    "                                          earlyStopping]\n",
    "                            )\n",
    "print 'terminou'\n",
    "print min(fitHistory.history['val_loss'])\n",
    "if min(fitHistory.history['val_loss']) < bestSimpleValLoss:\n",
    "    print 'entrou'\n",
    "    bestSimpleValLoss = min(fitHistory.history['val_loss'])\n",
    "    bestSimpleFitHistory = fitHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelCheckpointStd = ModelCheckpoint('tmp/PETR4_MLP_simple.h5', save_best_only=True)\n",
    "\n",
    "init_time = time.time()\n",
    "\n",
    "bestSimpleValLoss = np.Inf\n",
    "bestSimpleFitHistory = None\n",
    "\n",
    "for nNeurons in range(1, maxNeuronsInHiddenLayer + 1):\n",
    "    for fold in range(nFolds):\n",
    "        modelSimple = Sequential([Dense(nNeurons, activation = 'tanh', input_dim = inputDim),\n",
    "                                  Dense(1, activation = 'linear')\n",
    "                                 ])\n",
    "        modelSimple.compile(optimizer = optimizer, loss = 'mean_squared_error', metrics = ['mae'])\n",
    "\n",
    "        print 'começou'\n",
    "        fitHistory = modelSimple.fit(xSimpleTrain, \n",
    "                                     ySimpleTrain, \n",
    "                                     epochs = 500,\n",
    "                                     verbose = 0,\n",
    "                                     shuffle = True,\n",
    "                                     validation_split = 0.15, \n",
    "                                     callbacks = [modelCheckpointStd,\n",
    "                                                  earlyStopping]\n",
    "                                    )\n",
    "        print 'terminou'\n",
    "        \n",
    "        print min(fitHistory.history['val_loss'])\n",
    "        if min(fitHistory.history['val_loss']) < bestSimpleValLoss:\n",
    "            print 'entrou'\n",
    "            bestSimpleValLoss = min(fitHistory.history['val_loss'])\n",
    "            bestSimpleFitHistory = fitHistory\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "print 'Time to fit all models: '+str(end_time-init_time)+' seconds'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bestModelSimple = load_model('tmp/PETR4_MLP_simple.h5')\n",
    "bestModelSimple.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (10,10), nrows = 1, ncols = 1)\n",
    "ax.set_title('RMSE per epoch')\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('RMSE')\n",
    "trainigSet, = ax.plot(np.sqrt(bestSimpleFitHistory.history['loss']), 'b', label = 'trainig set')\n",
    "validationSet, = ax.plot(np.sqrt(bestSimpleFitHistory.history['val_loss']), 'r', label = 'validation set')\n",
    "plt.legend(handles=[trainigSet, validationSet], labels=['training set', 'validation set'], prop={'size': 15})\n",
    "plt.figtext(0.5,  0.010, 'Lowest Validation RMSE: {}'.format(min(bestSimpleFitHistory.history['val_loss'])), size = 14, horizontalalignment = 'center')\n",
    "fig.savefig('{}/{}.{}'.format(saveFigDir, 'PETR4_MLP_simple', 'pdf'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionsSimple = bestModelSimple.predict(xSimpleTest)\n",
    "predictionsSimple = ySimpleScaler.inverse_transform(predictionsSimple)\n",
    "predictionsSimple_clean = []\n",
    "for p in predictionsSimple:\n",
    "    predictionsSimple_clean.extend(p)\n",
    "predictionsSimpleSeries = pd.Series(predictionsSimple_clean, index = df['2017'].index)\n",
    "\n",
    "plotSeries([df['PETR4_Close_trend']+ df['PETR4_Close_resid'], \n",
    "#            df['PETR4_Close_trend'],\n",
    "            df['PETR4_Close_trend'] + predictionsSimpleSeries],\n",
    "           initialPlotDate = '2017-05', finalPlotDate = '2017-06',\n",
    "           title = 'Original Data vs Predicted', ylabel = 'Price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotSeries([df['PETR4_Close_resid'], (df['PETR4_Close_resid'] - predictionsSimpleSeries)],\n",
    "           plotZeroLine = True,\n",
    "           initialPlotDate = '2017-05', finalPlotDate = '2017-06',\n",
    "           title = 'Prediction Error', ylabel = 'BRL')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
